{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Fare Classification\n",
    "\n",
    "Download New York Fare dataset at Google Classroom\n",
    "\n",
    "Objectives \n",
    "- learn embeddings (done!)\n",
    "- learn dropout (done! yay!)\n",
    "- serve as another case study\n",
    "\n",
    "Embedding\n",
    "- a very powerful concept\n",
    "- replaces label-encoding and one-hot encoding\n",
    "  - label-encoding:  turns category into numbers\n",
    "  - one-hot encodings: turns category into cols\n",
    "- In neural network, we don't have to....\n",
    "  - we instead assign a vector of numbers for each category\n",
    "  - Let's say I have 1000 samples, one col with two categories (morning, afternoon)\n",
    "    - SHAPE: (1000, 1)\n",
    "  - But for neural network, we can first create random vectors representing each category\n",
    "    - morning:   [1, 5, 0.3, 2, 5]\n",
    "    - afternoon: [4, 3, 0.2, 1, 0.9]\n",
    "    - SHAPE: (1000, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuffs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/NYCTaxiFares.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "#1. convert UTC to New York time....\n",
    "#2. extract hours, am/pm, day as features\n",
    "#3. fare_class is our y/target/label\n",
    "#4. engineer some distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.666667\n",
       "1    0.333333\n",
       "Name: fare_class, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check class imbalance of data\n",
    "#the first thing you must do in any dataset\n",
    "df['fare_class'].value_counts(normalize=True)\n",
    "#0 means less than 10 dollars\n",
    "#1 means greater than equal to 10 dollars\n",
    "#upsampling - SMOTE\n",
    "#downsampling - I don't remember\n",
    "#I think there is a library imblearn - take a look\n",
    "#remember, if you use cross-validation, do it during cross-validation\n",
    "#basically, no data leakage........"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "We are lazy today....so skip...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "- create the distance column for us\n",
    "\n",
    "### Calculate the distance traveled\n",
    "The <a href='https://en.wikipedia.org/wiki/Haversine_formula'>haversine formula</a> calculates the distance on a sphere between two sets of GPS coordinates.<br>\n",
    "Here we assign latitude values with $\\varphi$ (phi) and longitude with $\\lambda$ (lambda).\n",
    "\n",
    "The distance formula works out to\n",
    "\n",
    "${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{align} r&: \\textrm {radius of the sphere (Earth's radius averages 6371 km)}\\\\\n",
    "\\varphi_1, \\varphi_2&: \\textrm {latitudes of point 1 and point 2}\\\\\n",
    "\\lambda_1, \\lambda_2&: \\textrm {longitudes of point 1 and point 2}\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi    = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column called hav_dis inside df using this function\n",
    "df['hav_dis'] = haversine_distance(df, 'pickup_latitude', \n",
    "                                       'pickup_longitude',\n",
    "                                       'dropoff_latitude', \n",
    "                                       'dropoff_longitude',)\n",
    "\n",
    "#don't put correlated features into the model\n",
    "#all features are assumed to be uncorrelated\n",
    "#ex:  height in inches and height in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean          3.322160\n",
       "std           3.337004\n",
       "min           0.010208\n",
       "25%           1.316428\n",
       "50%           2.237084\n",
       "75%           4.034564\n",
       "max          28.846365\n",
       "Name: hav_dis, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hav_dis'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='fare_class', ylabel='hav_dis'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#a little bit\n",
    "#bivariate analysis between hav_dis and fare_class\n",
    "import seaborn as sns\n",
    "sns.boxplot(x = df.fare_class, y = df.hav_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction\n",
    "\n",
    "1. convert UTC to New York time....\n",
    "2. extract hours, am/pm, day as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-04-19 08:17:56 UTC'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pickup_datetime'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the time difference between UTC and New York....\n",
    "df['new_york_time'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hour  - df['new_york_time'].dt.hour\n",
    "#day   - df['new_york_time'].dt.strftime(\"%a\")\n",
    "#am/pm - np.where(hour < 12, 'am', 'pm')\n",
    "#np.where(condition, if true, if false)\n",
    "df['hour'] = df['new_york_time'].dt.hour\n",
    "df['day']  = df['new_york_time'].dt.strftime(\"%a\")\n",
    "df['ampm'] = np.where(df['hour'] < 12, 'am', 'pm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['am', 'pm'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ampm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help me write a simple assert function\n",
    "#there should be no more than 24 hours\n",
    "assert len(df['hour'].unique()) <= 24, \"More than 24 hours\"\n",
    "assert df['hour'].min() == 0, \"Some negative hours!\"\n",
    "assert df['hour'].max() == 23, \"Not a normal time system~\"\n",
    "\n",
    "#there should be no more than 7 days\n",
    "assert len(df['day'].unique()) == 7, \"Something not Mon-Sun\"\n",
    "\n",
    "#there should be only am and pm\n",
    "assert (df['ampm'].unique() == np.array(['am', 'pm'])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Categorify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns name\n",
    "cat_cols  = ['hour', 'ampm', 'day']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', \n",
    "             'dropoff_latitude', 'dropoff_longitude',\n",
    "             'passenger_count', 'hav_dis'] \n",
    "y         = ['fare_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is a dtype called category\n",
    "#which gonna neatly turns our data into integers....\n",
    "#basically it's like label encoding, but much more\n",
    "#why we need to turn it into category first\n",
    "#because, the embedding is like for 0, 1, 2\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ampm'].cat.categories\n",
    "#df['ampm'].cat.codes\n",
    "#df['ampm'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime      0\n",
       "fare_amount          0\n",
       "fare_class           0\n",
       "pickup_longitude     0\n",
       "pickup_latitude      0\n",
       "dropoff_longitude    0\n",
       "dropoff_latitude     0\n",
       "passenger_count      0\n",
       "hav_dis              0\n",
       "new_york_time        0\n",
       "hour                 0\n",
       "day                  0\n",
       "ampm                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #let me guess, no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack the hours, ampm, and day as one vector\n",
    "\n",
    "hr   = df['hour'].cat.codes.values #[vectors of hours, e.g., 0, 4, 2]\n",
    "ampm = df['ampm'].cat.codes.values\n",
    "day  = df['day'].cat.codes.values\n",
    "\n",
    "time = np.stack([hr, ampm, day], 1)\n",
    "\n",
    "time[:5]\n",
    "\n",
    "time.shape  #(120000 samples, 3 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert this numpy into tensor\n",
    "time = torch.tensor(time, dtype=torch.int64)\n",
    "time[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_latitude',\n",
       " 'pickup_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'dropoff_longitude',\n",
       " 'passenger_count',\n",
       " 'hav_dis']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarly, we want to stack them into a vector of size 6\n",
    "lat1  = df['pickup_latitude'].values  #.values give you the numpy vector\n",
    "lat2  = df['dropoff_latitude'].values\n",
    "long1 = df['pickup_longitude'].values\n",
    "long2 = df['dropoff_longitude'].values\n",
    "ps_count = df['passenger_count'].values\n",
    "hav_dis  = df['hav_dis'].values\n",
    "#use list comprehension\n",
    "#[df[col].values for col in cont_cols]\n",
    "\n",
    "conts = np.stack([lat1, lat2, long1, long2, ps_count, hav_dis], 1)\n",
    "\n",
    "#turn this into tensor...\n",
    "conts = torch.tensor(conts, dtype=torch.float32)\n",
    "\n",
    "conts[:4]\n",
    "conts.shape  #(120000, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finally, we need the y, to be in tensor\n",
    "y = torch.tensor(df[y].values).flatten()  #reshape(-1)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Determine the embedding size\n",
    "\n",
    "- Before we create the embedding, we need to specify the embedding size....\n",
    "- Two ways:  \n",
    "  - randomly pick a size\n",
    "    - min(50, unique/2)\n",
    "  - specify a size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the size of all my categorical cols\n",
    "cat_size = [len(df[col].cat.categories) for col in cat_cols]\n",
    "#[24, 2, 7]  #[24, 7, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 3)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = [(size, min(50, size//2)) for size in cat_size]\n",
    "emb_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Try to illustrate how Embedding layer works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = time[:1]\n",
    "sample\n",
    "twosamples = time[:2]\n",
    "twosamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected output after embedding of sample\n",
    "#[  [[12 numbers]], [[1 number]], [[3 numbers]]]\n",
    "\n",
    "#expected output after embedding of sample\n",
    "#[  [[12 numbers], [12 numbers]],   [[1 number], [1 number]], \n",
    "#   [[3 numbers], [3 numbers]]    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb_size: [(24, 12), (2, 1), (7, 3)]\n",
    "#but pyTorch does not have a list of nn.Embedding\n",
    "#if you want pyTorch to have a list of layers, use nn.ModuleList\n",
    "embed_layer = nn.ModuleList([nn.Embedding(unique, emb_s) for unique, emb_s in emb_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 3)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty embedding\n",
    "sample_embedding = []\n",
    "\n",
    "for i, e in enumerate(embed_layer):\n",
    "    sample_embedding.append(e(twosamples[:, i])) #apply embedding layer to column i\n",
    "                                                 #apply embedding layer 0 to column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.5484,  0.7046, -1.4978,  0.6189, -1.2653,  0.5839, -0.3792, -1.4074,\n",
       "          -1.4290,  0.7603, -0.0536, -0.3382],\n",
       "         [ 0.0700, -0.6868,  1.2135, -0.3694,  0.7244,  1.8583, -0.9326, -1.4131,\n",
       "          -0.2410,  1.8036, -0.5810, -1.9466]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.0223],\n",
       "         [-0.0223]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-1.3015, -0.3615,  0.7095],\n",
       "         [ 0.0879,  0.9857, -0.1703]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5484,  0.7046, -1.4978,  0.6189, -1.2653,  0.5839, -0.3792, -1.4074,\n",
       "         -1.4290,  0.7603, -0.0536, -0.3382, -0.0223, -1.3015, -0.3615,  0.7095],\n",
       "        [ 0.0700, -0.6868,  1.2135, -0.3694,  0.7244,  1.8583, -0.9326, -1.4131,\n",
       "         -0.2410,  1.8036, -0.5810, -1.9466, -0.0223,  0.0879,  0.9857, -0.1703]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in coding, we want to concat all these embeddings, into one vector\n",
    "final_embedding = torch.cat(sample_embedding, 1)\n",
    "\n",
    "final_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gonna teach you very briefly about nn.Dropout\n",
    "#define a dropout layer\n",
    "dl = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0967,  1.4091, -2.9956,  0.0000, -0.0000,  1.1677, -0.7583, -2.8148,\n",
       "         -2.8580,  1.5206, -0.0000, -0.6765, -0.0000, -2.6031, -0.7230,  1.4190],\n",
       "        [ 0.0000, -1.3736,  2.4270, -0.0000,  0.0000,  3.7166, -1.8651, -0.0000,\n",
       "         -0.0000,  0.0000, -1.1620, -3.8931, -0.0446,  0.0000,  1.9714, -0.3405]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embedding = dl(final_embedding)\n",
    "final_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305,  40.7447, -73.9924, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406,  40.7441, -73.9901, -73.9742,   1.0000,   1.3923]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cont = conts[:2]\n",
    "sample_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format: nn.BatchNorm1d(features)\n",
    "batch_norm1d = nn.BatchNorm1d(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8464,  0.0995, -0.3372, -0.1966,  0.0000,  1.0000],\n",
       "        [ 0.8456, -0.0997,  0.3414,  0.1961,  0.0000, -1.0000]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = batch_norm1d(sample_cont)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_embedding (120000, 16)\n",
    "#cont          (120000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class someNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_size, cont_size, out_size, layer_size = [200, 100], p=0.5):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.ModuleList([nn.Embedding(unique, emb_s) for unique, emb_s in emb_size])\n",
    "        self.dropout     = nn.Dropout(p)\n",
    "        self.batchnorm1d = nn.BatchNorm1d(cont_size)\n",
    "        \n",
    "        #calculate input_size\n",
    "        cat_size = sum(emb_s for _, emb_s in emb_size)\n",
    "        input_size = cat_size + cont_size\n",
    "        \n",
    "        #linear(input_size, 200) -> relu -> batchnorm -> dropout\n",
    "        #linear(200, 100) -> relu -> batchnorm -> dropout\n",
    "        #linear(100, out_size)\n",
    "        layerlist = []\n",
    "        for i in layer_size:\n",
    "            layerlist.append(nn.Linear(input_size, i))  #(input_size, 200)\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "        layerlist.append(nn.Linear(layer_size[-1], out_size))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "            \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        #x_cat:  (120000, 3)\n",
    "        #x_cont: (120000, 6)\n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.embed_layer):\n",
    "            embeddings.append(e(x_cat[:, i]))\n",
    "        x = torch.cat(embeddings, 1)  \n",
    "        #x: (120000, 16)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x_cont = self.batchnorm1d(x_cont)  \n",
    "        #x_cont: (120000, 6)\n",
    "        \n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        #x: (120000, 24)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = someNN(emb_size, conts.shape[1], len(y.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's test\n",
    "#random dataset\n",
    "sample_size = 3\n",
    "cat_size    = 3\n",
    "cont_size   = 6\n",
    "\n",
    "p = 0.5\n",
    "x_cat_hour  = torch.randint(0, 24,(sample_size, 1))\n",
    "x_cat_ampm  = torch.randint(0, 2, (sample_size, 1))\n",
    "x_cat_day   = torch.randint(0, 7, (sample_size, 1))\n",
    "x_cat_example      = torch.cat([x_cat_hour, x_cat_ampm, x_cat_day], 1)\n",
    "x_cont_example     = torch.randn(sample_size, cont_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13,  1,  5],\n",
       "        [ 7,  1,  6],\n",
       "        [ 5,  1,  3]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cat_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7153, -0.2527,  0.3399,  0.0503, -0.3588, -0.7699],\n",
       "        [-0.5230,  1.4375,  0.2547,  0.0185, -2.2835,  0.6144],\n",
       "        [ 1.1439, -0.6728, -0.5194, -0.7693,  0.6107,  1.5501]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cont_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x_cat_example, x_cont_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8262,  1.1781],\n",
       "        [-0.4123, -0.7688],\n",
       "        [ 0.9569, -0.0365]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Training!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function \n",
    "J_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizer (you can try use Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "#Adam have dynamic learning schedules....\n",
    "#but it is NOT proven that Adam is better than SGD...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why you not use 120000, too lazy to wait\n",
    "#why you don't use dataloader, because our data is small, only 9 features....\n",
    "\n",
    "#train test split\n",
    "train_size = 60000\n",
    "test_size  = 12000\n",
    "\n",
    "#use your numpy indexing technique\n",
    "cat_train = time[:train_size]\n",
    "cat_test  = time[train_size:test_size+train_size]\n",
    "con_train = conts[:train_size]\n",
    "con_test  = conts[train_size:test_size+train_size]\n",
    "y_train   = y[:train_size]\n",
    "y_test    = y[train_size:test_size+train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5479730367660522\n",
      "Loss: 0.2863588333129883\n",
      "Loss: 0.27373749017715454\n",
      "Loss: 0.2667602300643921\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    yhat = model(cat_train, con_train)\n",
    "    loss = J_fn(yhat, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 25 == 1:\n",
    "        print(f\"Epoch: {i}; Loss: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [loss.item() for loss in losses]\n",
    "# train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14413be50>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Testing/Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    yhat = model(cat_test, con_test)\n",
    "    loss = J_fn(yhat, y_test)\n",
    "    predicted = torch.max(yhat, 1)[1]\n",
    "    acc  = accuracy_score(predicted, y_test)\n",
    "    \n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
