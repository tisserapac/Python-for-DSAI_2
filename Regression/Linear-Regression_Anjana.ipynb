{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1\n",
    "x1 = np.array([3, 100, 4])\n",
    "y1 = np.array([21])\n",
    "\n",
    "# What is the idea of prediction? What is machine learning?\n",
    "# -> Find the weight that can bring you from x1 to y1\n",
    "\n",
    "# 3 * w1 + 100 * w2 + 4 * w3 = 21\n",
    "\n",
    "# Machine learning is trying to find 'best' weights\n",
    "# These best weights across all samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[3, 100, 4] , [4,500, 7]])\n",
    "X.shape #(2,3) means 2 samples = m, 3 features = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights = theta = params\n",
    "theta = np.array([7,1,-25])\n",
    "theta.shape # Weights must be the sample shape as X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21, 353])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X @ theta (X.dot theta )\n",
    "# Dot product- same number in close pair\n",
    "#(4,6,1) @ (1, 2 ) = (4,6,1,2)\n",
    "\n",
    "X @ theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of terms and notations\n",
    "\n",
    "#2 samples\n",
    "#3 features - egg price, gold price, oil price\n",
    "    #features are the variables used for predicting the label\n",
    "    #factors, independent variables, predictors, X\n",
    "\n",
    "#egg price - x_1 --> always a vector,  e.g., [3, 4]\n",
    "#gold price - x_2 --> always a vector, e.g., [100, 500]\n",
    "#oil price - x_3 --> always a vector, e.g., [4, 7]\n",
    "#we call egg price + gold price + oil price - whole `feature matrix` --> \\mathbf{X}\n",
    "    \n",
    "#1 label - gdp\n",
    "    #label is the variable that we want to predict....\n",
    "    #target, outcome, y\n",
    "    #y_1 = y = a vector of labels, e.g., [21, 43]\n",
    "    \n",
    "#Tips: small and big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math notations:\n",
    "\n",
    "- normal a -> scalar (one number)\n",
    "- bold  $\\mathbf{a}$  --> vector (a 1D numpy array)\n",
    "- bold  $\\mathbf{A}$  --> matrix (a 2D numpy array....)\n",
    "\n",
    "- $\\mathbf{x}_1^2$  --> feature 1, second sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the best weight?\n",
    "\n",
    "- There are many ways, e.g., closed form, gradient descent, expectation\n",
    "- gradient descent / backpropagation\n",
    "  - You adjust the weight slightly, based on the errors....\n",
    "  - How to adjust based on the errors\n",
    "\n",
    "0. You first use any randomized weight\n",
    "   \n",
    "   [1, 2, 3]\n",
    "\n",
    "1. We need to find out how to measure errors\n",
    "\n",
    "$\\sum_0^m (\\hat{y}_i - y_i)^2 $\n",
    "\n",
    "2. We need to know how much to adjust the weight?  HOW?\n",
    "\n",
    "- Just try all numbers in the world..... ---> NO\n",
    "\n",
    "- Find the derivative first!\n",
    "\n",
    "3. We need to change the weight accordingly\n",
    "\n",
    "- Weight = weight - $\\alpha$ * derivative\n",
    "\n",
    "- $\\alpha$ = 0.1, 0.01, 0.001,...\n",
    "\n",
    "4. Run predict again....\n",
    "\n",
    "5. We stop when our errors are decreased no more....or reach some max iterations...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'error/cost')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(0, 100, 1000)\n",
    "y = (x - 50) ** 2\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"weights\")\n",
    "plt.ylabel(\"error/cost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "#print the shape of X and y\n",
    "X.shape, y.shape\n",
    "\n",
    "assert X.ndim == 2\n",
    "assert y.ndim == 1\n",
    "\n",
    "#print one row of X, and maybe try to see what it is...\n",
    "#X[0]\n",
    "#y[0]\n",
    "print(diabetes.feature_names)\n",
    "\n",
    "# Label is blood glucouse level\n",
    "\n",
    "#print one row of y, and maybe try to see what it is....\n",
    "\n",
    "#please help me set m and \n",
    "m = X.shape[0] # Number of samples\n",
    "n = X.shape[1] # Number of features\n",
    "m,n\n",
    "\n",
    "#write an assert function to check that X and y has same amount of samples...\n",
    "assert m == y.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=999)\n",
    "\n",
    "# Assert X_train and y_train has same ammount of samples\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "\n",
    "# Assert X_test and y_test has same ammount of samples\n",
    "assert X_test.shape[0] == y_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Satndadize the trainning set\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "# Standardize the test set\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Add intercept to your X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: if your X is        [  [3, 2, 4],    [2, 6, 8]  ]\n",
    "# I want you to make it into   [  [1, 3, 2, 4], [1, 2, 6, 8]  ]\n",
    "# Why 1?  because imagine you have another weight, which let's call w0\n",
    "# this w0 is actually the intercept; so multiply with 1, will do nothing\n",
    "# so we can still use X @ theta....\n",
    "\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "intercept.shape\n",
    "\n",
    "#hint: use np.concatenate with X_train on axis=1, to add these ones to X_train\n",
    "X_train = np.concatenate((intercept, X_train), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 11)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "intercept.shape\n",
    "\n",
    "X_test = np.concatenate((intercept, X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 11)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fitting!!! Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put everything fit()\n",
    "\n",
    "#1. randomize our theta\n",
    "#please help me create a random theta of size (X_train.shape[1], )\n",
    "theta = np.ones(X_train.shape[1])\n",
    "#why X_train.shape[1]\n",
    "\n",
    "#5. repeat 2, 3, 4\n",
    "#please put a for loop for 2, 3, 4, for 1000 times\n",
    "#set 1000 call it max_iter\n",
    "#for _ in range(max_iter):\n",
    "max_iter = 1000\n",
    "alpha = 0.0001\n",
    "\n",
    "def predict(X, theta):\n",
    "    return X @ theta\n",
    "\n",
    "def mean_squared_error(ytrue, ypred):\n",
    "    return ((ypred - ytrue) ** 2).sum() / ytrue.shape[0]\n",
    "\n",
    "def _grad(X, error):\n",
    "    return X.T @ error\n",
    "\n",
    "def fit(X_train, y_train, theta, max_iter, alpha):\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        #2. predict\n",
    "        yhat = predict(X_train, theta)  #put this into a function called predict(X_train, theta)\n",
    "\n",
    "        #2.1 can you guys compute the squared error\n",
    "        # squared_error = ((yhat - y_train) ** 2).sum()\n",
    "        #print the mean squared error, we can see whether MSE goes down eventually...\n",
    "        mse =  mean_squared_error(y_train, yhat)\n",
    "        if(i % 50 == 0):\n",
    "            print(f\"MSE: {mse}\")  \n",
    "\n",
    "        #3. get derivatives\n",
    "        deriv = _grad(X_train, yhat - y_train)\n",
    "\n",
    "        #4. update weight\n",
    "        theta = theta - alpha * deriv\n",
    "        \n",
    "    return theta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 30046.31881174594\n",
      "MSE: 4206.414663753659\n",
      "MSE: 3146.4187524734234\n",
      "MSE: 3096.56099093493\n",
      "MSE: 3092.4423530589784\n",
      "MSE: 3090.7457848318663\n",
      "MSE: 3089.3093029548677\n",
      "MSE: 3087.9775768316204\n",
      "MSE: 3086.723718999417\n",
      "MSE: 3085.535594108654\n",
      "MSE: 3084.404775758596\n",
      "MSE: 3083.324675874108\n",
      "MSE: 3082.289978994901\n",
      "MSE: 3081.2963455330882\n",
      "MSE: 3080.3402039692637\n",
      "MSE: 3079.4185916127904\n",
      "MSE: 3078.5290297915208\n",
      "MSE: 3077.66942549067\n",
      "MSE: 3076.83799371986\n",
      "MSE: 3076.033196201499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([156.98058252,   2.27084632, -12.19482609,  22.63910378,\n",
       "        14.49359804, -12.49568854,   6.18459067,  -6.29424872,\n",
       "         4.50181477,  28.04584342,   3.53515318])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = fit(X_train, y_train, theta, max_iter, alpha)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2487.362361336741"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = predict(X_test, theta)\n",
    "\n",
    "mean_squared_error(y_test, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "class LinearRegression(object):\n",
    "\n",
    "    kfold = KFold(n_splits=5)\n",
    "        \n",
    "    def __init__(self, alpha=0.001, num_epochs=5, batch_size=50, method='batch', cv=kfold):\n",
    "        self.max_iter   = max_iter\n",
    "        self.alpha      = alpha\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.method = method\n",
    "        self.cv = cv\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        #Using training\n",
    "\n",
    "        #Please change it to cross-validation\n",
    "\n",
    "        # List of kfold scores\n",
    "        self.kfold = list()\n",
    "\n",
    "        #K-fold.split in sklearn\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X_train)):\n",
    "\n",
    "            X_cross_train = X_train[train_idx]\n",
    "            y_cross_train = y_train[train_idx]\n",
    "            X_cross_val = X_train[val_idx]\n",
    "            y_cross_val = y_train[val_idx]\n",
    "            \n",
    "            #create self.theta here\n",
    "            self.theta = np.zeros(X_train.shape[1])            \n",
    "            \n",
    "            #define X_train as only a subset of the data\n",
    "            #how big is this subset?  => mini-batch size ==> 50\n",
    "            \n",
    "            for epoch in range(self.num_epochs):\n",
    "            \n",
    "                #with replacement or no replacement\n",
    "                #with replacement means just randomize\n",
    "                #with no replacement means 0:50, 51:100, 101:150, ......300:323\n",
    "                #shuffle your index\n",
    "                #===> please shuffle your index\n",
    "                perm = np.random.permutation(X_train.shape[0])\n",
    "                        \n",
    "                X_train = X_train[perm]\n",
    "                y_train = y_train[perm]\n",
    "\n",
    "                if self.method == 'sto':\n",
    "                    for batch_idx in range(X_train.shape[0]):\n",
    "                        X_method_train = X_train[batch_idx].reshape(1,-1) #(11,0) ==> (11,1)\n",
    "                        y_method_train = y_train[batch_idx]\n",
    "                        self._train(X_method_train, y_method_train)\n",
    "                elif self.method == 'mini':\n",
    "                    for batch_idx in range(0, X_train.shape[0], self.batch_size):                \n",
    "                        X_method_train = X_train[batch_idx:batch_idx+self.batch_size, :]\n",
    "                        y_method_train = y_train[batch_idx:batch_idx+self.batch_size]\n",
    "                        self._train(X_method_train, y_method_train)\n",
    "                else:\n",
    "                    X_method_train = X_train\n",
    "                    y_method_train = y_train\n",
    "                    self._train(X_method_train, y_method_train)\n",
    "            \n",
    "            #print the validation mse  \n",
    "            yhat_val = self.predict(X_cross_val)  \n",
    "            self.kfold.append(mean_squared_error(y_cross_val, yhat_val))\n",
    "            print(f\"Fold: {fold}: {mean_squared_error(y_cross_val, yhat_val)}\")\n",
    "\n",
    "    \n",
    "    def _train(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        grad = X.T @ (yhat - y)\n",
    "        self.theta = self.theta - self.alpha * grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.theta\n",
    "    \n",
    "    def _coef(self):\n",
    "        return self.theta[1:]\n",
    "        \n",
    "    def _bias(self):\n",
    "        return self.theta[0]        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(method='sto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0: 4576.551952445295\n",
      "Fold: 1: 4339.441603603833\n",
      "Fold: 2: 4112.492671865431\n",
      "Fold: 3: 3756.0612448296615\n",
      "Fold: 4: 5194.321828548474\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3191.746150030711"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.09815574, -7.88661367, 20.11238264, 12.70520493,  0.43979203,\n",
       "       -2.4781156 , -8.8214922 ,  7.23143671, 18.33841116,  7.26479454])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr._coef()  #the weight associated with the ten features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.67057047016428"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr._bias() #the bias or the intercept "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27768773b483d82a9b2b839e3fa80b1be5789db7fd78df4eedef2df266871616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
