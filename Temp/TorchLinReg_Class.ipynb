{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ETL \n",
    "   1. Specifying some some random input\n",
    "   2. PyTorch Dataset and DataLoader\n",
    "2. EDA - we gonna just skip because we are lazy...\n",
    "3. Feature Engineering / Cleaning - which we don't need to....\n",
    "4. Modeling \n",
    "   1. `nn.Linear` (luckily, you already understand this!  Yay!)\n",
    "   2. Define loss function (mse for regression, cross entrophy for classification)\n",
    "   3. Define the optimizer function (gradient descent ; adam)\n",
    "   4. Train the model\n",
    "5. Inference / Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X(temp, rainfall, hum)\n",
    "\n",
    "X_train = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
    "                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "Y_train = np.array([[56, 70], [81, 101], [119, 133], \n",
    "                    [22, 37], [103, 119], [56, 70], \n",
    "                    [81, 101], [119, 133], [22, 37], \n",
    "                    [103, 119], [56, 70], [81, 101], \n",
    "                    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(X_train)\n",
    "targets = torch.tensor(Y_train)\n",
    "ds = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3 # Can be any number\n",
    "# Too small - slow\n",
    "# Too large - run out of memory\n",
    "dl = DataLoader(ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class is the perfect and the best practice for creating a neural network of any type...\n",
    "\n",
    "#format:\n",
    "'''\n",
    "class AnyNameCapitalized(nn.Module): #it must inherit nn.Module\n",
    "    def __init__():\n",
    "        super().__init__()  #super is basically inheriting nn.Module init\n",
    "        #we define all the layers here.....\n",
    "        \n",
    "    def forward(self, x):   #YOU CANNOT CHANGE THIS NAME, it MUST BE \"forward\"\n",
    "        x = layer1()\n",
    "        x = layer2()\n",
    "        return x\n",
    "'''\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(  3  ,  10   ,  2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (fc1): Linear(in_features=3, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so how do we use our model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#under the nn module, there are many loss function\n",
    "J_fn = nn.MSELoss()\n",
    "\n",
    "#later on, you will know how to use this....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally in skleran we call fit, it will perform gradient descent\n",
    "# In code from scratch we need to like specify how we want to update the gradients\n",
    "# Optimizer handles how we update the parameters\n",
    "# If we use w = w -alpha (gradient) ==> gradient descent\n",
    "#Stochastic gradient descent ==>  is not one sample - mini-batch\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 8127.064453125\n",
      "Epoch: 0 - Loss: 12062.1494140625\n",
      "Epoch: 0 - Loss: 11792.26171875\n",
      "Epoch: 0 - Loss: 1892.9664306640625\n",
      "Epoch: 0 - Loss: 7108.32666015625\n",
      "Epoch: 1 - Loss: 9291.6806640625\n",
      "Epoch: 1 - Loss: 9601.4580078125\n",
      "Epoch: 1 - Loss: 9599.8974609375\n",
      "Epoch: 1 - Loss: 4340.59326171875\n",
      "Epoch: 1 - Loss: 8113.89599609375\n",
      "Epoch: 2 - Loss: 9595.7099609375\n",
      "Epoch: 2 - Loss: 5661.01953125\n",
      "Epoch: 2 - Loss: 9281.0234375\n",
      "Epoch: 2 - Loss: 10717.3466796875\n",
      "Epoch: 2 - Loss: 5657.48388671875\n",
      "Epoch: 3 - Loss: 10713.8798828125\n",
      "Epoch: 3 - Loss: 7836.72412109375\n",
      "Epoch: 3 - Loss: 12032.72265625\n",
      "Epoch: 3 - Loss: 5652.61376953125\n",
      "Epoch: 3 - Loss: 4641.80810546875\n",
      "Epoch: 4 - Loss: 4641.1748046875\n",
      "Epoch: 4 - Loss: 6774.42431640625\n",
      "Epoch: 4 - Loss: 10854.0849609375\n",
      "Epoch: 4 - Loss: 6818.201171875\n",
      "Epoch: 4 - Loss: 11754.9345703125\n",
      "Epoch: 5 - Loss: 8403.265625\n",
      "Epoch: 5 - Loss: 2886.538330078125\n",
      "Epoch: 5 - Loss: 7079.423828125\n",
      "Epoch: 5 - Loss: 9256.7431640625\n",
      "Epoch: 5 - Loss: 13182.015625\n",
      "Epoch: 6 - Loss: 7075.08935546875\n",
      "Epoch: 6 - Loss: 6646.435546875\n",
      "Epoch: 6 - Loss: 7072.71484375\n",
      "Epoch: 6 - Loss: 15664.7841796875\n",
      "Epoch: 6 - Loss: 4314.16162109375\n",
      "Epoch: 7 - Loss: 5796.609375\n",
      "Epoch: 7 - Loss: 5319.54443359375\n",
      "Epoch: 7 - Loss: 10828.2138671875\n",
      "Epoch: 7 - Loss: 10723.9765625\n",
      "Epoch: 7 - Loss: 8069.91796875\n",
      "Epoch: 8 - Loss: 4308.37158203125\n",
      "Epoch: 8 - Loss: 9550.46484375\n",
      "Epoch: 8 - Loss: 9234.71484375\n",
      "Epoch: 8 - Loss: 5625.26708984375\n",
      "Epoch: 8 - Loss: 11984.7177734375\n",
      "Epoch: 9 - Loss: 6791.58154296875\n",
      "Epoch: 9 - Loss: 9492.7080078125\n",
      "Epoch: 9 - Loss: 11978.6943359375\n",
      "Epoch: 9 - Loss: 6623.71337890625\n",
      "Epoch: 9 - Loss: 5782.10400390625\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10 \n",
    "for epoch in range(num_epochs):\n",
    "    for x, y in dl:  \n",
    "        x.to(device)  #device is either cpu or cuda\n",
    "        y.to(device)\n",
    "\n",
    "        yhat = model(x)\n",
    "        loss = J_fn(yhat, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()  \n",
    "        optim.step()  \n",
    "        \n",
    "        print(f\"Epoch: {epoch} - Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[73., 67., 43.],\n",
       "         [91., 88., 64.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6018.6230, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#please create two numpy array of \n",
    "# [74, 68, 42], [92, 88, 65]\n",
    "x = np.array([[74, 68, 42], [92, 88, 65]], dtype='float32')\n",
    "#float  means 32 bits\n",
    "#double means 64 bits\n",
    "\n",
    "#please make it a tensor\n",
    "x_tensor = torch.tensor(x)\n",
    "\n",
    "#then use our model to predict the number of oranges and apples\n",
    "yhat = model(x_tensor)\n",
    "yhat\n",
    "\n",
    "#print the loss comparing with ds[0] and ds[1] - look at the y part ok...\n",
    "ytest = ds[0:2][1]\n",
    "loss = J_fn(yhat, ytest)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27768773b483d82a9b2b839e3fa80b1be5789db7fd78df4eedef2df266871616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
