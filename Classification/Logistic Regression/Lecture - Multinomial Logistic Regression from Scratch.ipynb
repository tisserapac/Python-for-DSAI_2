{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## Multinomial Logistic Regression from Scratch\n",
    "\n",
    "### Readings: \n",
    "- [GERON] Ch4\n",
    "- [VANDER] Ch5\n",
    "- [HASTIE] Ch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression\n",
    "\n",
    "This is logistic regression when number of classes are more than 2.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The gradient descent has the following steps:\n",
    "\n",
    "1. Prepare your data\n",
    "    - add intercept\n",
    "    - $\\mathbf{X}$ and $\\mathbf{Y}$ and $\\mathbf{W}$ in the right shape\n",
    "        - $\\mathbf{X}$ -> $(m, n)$\n",
    "        - $\\mathbf{Y}$ -> $(m, k)$\n",
    "        - $\\mathbf{W}$ -> $(n, k)$\n",
    "        - where $k$ is number of classes\n",
    "    - train-test split\n",
    "    - feature scale\n",
    "    - clean out any missing data\n",
    "    - (optional) feature engineering\n",
    "2. Predict using the softmax function\n",
    "   $$ h = P(y = c \\mid \\boldsymbol{\\theta}) = \\frac{e^{\\boldsymbol{\\theta}^{T}_c\\mathbf{x}}}{\\Sigma_{i=1}^{k} e^{\\boldsymbol{\\theta}_k^{T}\\mathbf{x}}}$$\n",
    "   where c is the class\n",
    "   \n",
    "   --->why this function?<----\n",
    "   - First, mathematically, this is just an extension of the sigmoid formula for multi-class classification\n",
    "   - $e$ will always give non-negative outputs which helps, since probability is never negative\n",
    "   - $e$ has a similar effect as argmax, which will turn larger input to larger outputs.\n",
    "   - $e$ is super easy to differentiate, because derivative of $e$ is $e$\n",
    "   - $e$ nicely cancel out the $\\log$ in the cross entropy loss (see below)\n",
    "   - By dividing, it make sure all the probability adds up to one.  You can think the softmax function as some form of normalization.   Why not normalization?  Because normalization cares only about proportion, while softmax reacts to change in scale better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (2, 3)\n",
      "Y:  (2, 4)\n",
      "W:  (3, 4)\n",
      "X @ W: [[ 8 14 20  7]\n",
      " [15 26 35 13]]\n",
      "softmax(X @ W): [[6.12896865e-06 2.47260243e-03 9.97519014e-01 2.25472156e-06]\n",
      " [2.06089928e-09 1.23394576e-04 9.99876603e-01 2.78912388e-10]]\n",
      "Try to confirm it adds up to 1: [1. 1.]\n",
      "if I want to know which one is the answer, use argmax:  [2 2]\n",
      "normalization(X @ W): [[0.30044631 0.52578104 0.75111577 0.26289052]\n",
      " [0.31311215 0.54272772 0.73059501 0.27136386]]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "\n",
    "X = np.array([[1, 2, 3],\n",
    "             [2, 4, 5]])\n",
    "\n",
    "print(\"X: \", X.shape)  #(m, n) two samples, three features.  We ignore the y-intercept\n",
    "\n",
    "#####important########\n",
    "#note that Y in a multi-class classification is one-hot NOT class label\n",
    "Y = np.array([[0, 0, 1, 0],\n",
    "              [1, 0, 0, 0]])  #(m, k) let's say four classes\n",
    "\n",
    "print(\"Y: \", Y.shape)\n",
    "\n",
    "W = np.array([[1, 2, 3, 4],\n",
    "              [2, 3, 1, 0],\n",
    "              [1, 2, 5, 1],\n",
    "              ])  #(n, k)  three features, four classes\n",
    "\n",
    "print(\"W: \", W.shape)\n",
    "\n",
    "print(\"X @ W:\",  X @ W)  #X @ W should be the same shape as our y\n",
    "\n",
    "print(\"softmax(X @ W):\", softmax(X@W))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"Try to confirm it adds up to 1:\", softmax(X@W).sum(axis=1))\n",
    "\n",
    "print(\"if I want to know which one is the answer, use argmax: \", np.argmax(softmax(X@W), axis=1))\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "print(\"normalization(X @ W):\", normalize(X@W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate the loss using the cross entropy loss\n",
    "    $$J = -\\sum_{i=1}^m y^{(i)}\\log(h^{(i)})$$\n",
    "    \n",
    "Note that this is no different with the previous binary cross entropy loss.  The binary cross entropy loss is now simply extended to multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  [[0 0 1 0]\n",
      " [1 0 0 0]]\n",
      "h:  [[0.00000613 0.0024726  0.99751901 0.00000225]\n",
      " [0.         0.00012339 0.9998766  0.        ]]\n",
      "log:  [[ -0.          -0.          -0.00248407  -0.        ]\n",
      " [-20.0001234   -0.          -0.          -0.        ]]\n",
      "log loss:  [[ 0.          0.          0.00248407  0.        ]\n",
      " [20.0001234   0.          0.          0.        ]]\n",
      "sum of log loss:  20.00260747339262\n"
     ]
    }
   ],
   "source": [
    "print(\"Y: \", Y)\n",
    "print(\"h: \", softmax(X@W))\n",
    "print(\"log: \", Y * np.log(softmax(X@W)))\n",
    "print(\"log loss: \", -(Y * np.log(softmax(X@W))))\n",
    "print(\"sum of log loss: \", np.sum(-(Y * np.log(softmax(X@W)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calculate the gradient of theta of feature $j$ based on the loss function $J$\n",
    "    - Suppose given 2 classes (k = 2) and 3 features (n = 3), first, our y will have shape of (sample, 2), where $y_1$ refers to the probability of the sample belonging to class 1, and $y_2$ is the probability of the sample belonging to class 2.  Here $y$ sums to 1.  We have the loss function as\n",
    "       $$ J = -y_1 \\log h_1 - y_2 \\log h_2 $$\n",
    "       where $h_1$ and $h_2$ are\n",
    "       $$ h_1 = \\frac{\\exp(g_1)}{\\exp(g_1)+\\exp(g_2)} $$\n",
    "       $$ h_2 = \\frac{\\exp(g_2)}{\\exp(g_1)+\\exp(g_2)} $$\n",
    "       where $g_1$ and $g_2$ are\n",
    "       $$ g_1 = w_{11}x_1 + w_{21}x_2 + w_{31}x_3 $$\n",
    "       $$ g_2 = w_{12}x_1 + w_{22}x_2 + w_{32}x_3  $$\n",
    "       where in $w_{ij}$, $i$ stands for feature and $j$ stands for class \n",
    "    - For example, to find the gradient of $J$ in respect to $w_{21}$, we simply can use the chain rule (or backpropagation) to calculate like this:\n",
    "       $$ \\frac{\\partial J}{\\partial w_{21}} = \\frac{\\partial J}{\\partial h_{1}}\\frac{\\partial h_{1}}{\\partial g_{1}}\\frac{\\partial g_{1}}{\\partial w_{21}} + \\frac{\\partial J}{\\partial h_{2}}\\frac{\\partial h_{2}}{\\partial g_{1}}\\frac{\\partial g_{1}}{\\partial w_{21}}$$\n",
    "   - If we know each of them, it is easy, where\n",
    "       $$\\frac{\\partial J}{\\partial h_{1}} = -\\frac{y_1}{h_1}$$\n",
    "       $$\\frac{\\partial J}{\\partial h_{2}} = -\\frac{y_2}{h_2}$$\n",
    "       $$\\frac{\\partial h_{1}}{\\partial g_{1}} = \\frac{\\exp(g_{1})}{\\exp(g_{1}) + \\exp(g_{2})} - (\\frac{\\exp(g_1)}{\\exp(g_1)+\\exp(g_2)})^2 = h_1 (1 - h_1)$$\n",
    "       $$\\frac{\\partial h_{2}}{\\partial g_{1}} = \\frac{-exp(g_2)exp(g_1)}{(\\exp(g_1) + \\exp(g_2)^2} = -h_2h_1$$\n",
    "       $$\\frac{\\partial g_1}{\\partial w_{21}} = x_2$$\n",
    "    - For those who forgets how to do third and fourth, recall that the quotient rule\n",
    "        $$ (\\frac{f}{g})' = \\frac{f'g - fg'}{g^2}$$\n",
    "    - Putting everything together, we got\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial J}{\\partial w_{21}} &= \\frac{\\partial J}{\\partial h_{1}}\\frac{\\partial h_{1}}{\\partial g_{1}}\\frac{\\partial g_{1}}{\\partial w_{21}} + \\frac{\\partial J}{\\partial h_{2}}\\frac{\\partial h_{2}}{\\partial g_{1}}\\frac{\\partial g_{1}}{\\partial w_{21}}\\\\\n",
    "&= -\\frac{y_1}{h_1} * h_1 (1 - h_1) * x_2 + -\\frac{y_2}{h_2} * -h_2h_1 * x_2 \\\\\n",
    "&= x_2 (-y_1 + y_1h_1 + y_2h_1)\\\\\n",
    "&= x_2 (-y_1 + h_1(y_1 + y_2))\\\\\n",
    "&= x_2 (h_1 - y_1)\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "4. Update the theta with this update rule\n",
    "    $$\\theta_j := \\theta_j - \\alpha * \\frac{\\partial J}{\\partial \\theta_j}$$\n",
    "    where $\\alpha$ is a typical learning rate range between 0 and 1\n",
    "5. Loop 2-4 until max_iter is reached, or the difference between old loss and new loss are smaller than some predefined threshold tol\n",
    "\n",
    "**Note: Again, take it easy if you don't understand the derivative.  One good news is that the gradient turns out to be the same as past lesson!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Step 1: Prepare data\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, 2:]  # we only take the first two features.\n",
    "y = iris.target  #now our y is three classes thus require multinomial\n",
    "\n",
    "# data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# feature scaling helps improve reach convergence faster\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# add intercept to our X\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train   = np.concatenate((intercept, X_train), axis=1)  #add intercept\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test    = np.concatenate((intercept, X_test), axis=1)  #add intercept\n",
    "\n",
    "# make sure our y is in the shape of (m, k)\n",
    "# we will convert our output vector in \n",
    "# matrix where no. of columns is equal to the no. of classes. \n",
    "# The values in the matrix will be 0 or 1. For instance the rows \n",
    "# where we have output 2 the column 2 will contain 1 and the rest are all 0.\n",
    "# in simple words, y will be of shape (m, k)\n",
    "k = len(set(y))  # no. of class  (can also use np.unique)\n",
    "m = X_train.shape[0]  # no.of samples\n",
    "n = X_train.shape[1]  # no. of features\n",
    "Y_train_encoded = np.zeros((m, k))\n",
    "for each_class in range(k):\n",
    "    cond = y_train==each_class\n",
    "    Y_train_encoded[cond, each_class] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1.1 (optional): Visualize our data\n",
    "\n",
    "# your code here\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X[:, 0], X[:, 1], label='class 0', c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0 1.019647659063904\n",
      "Cost at iteration 500 0.0988357133475733\n",
      "Cost at iteration 1000 0.09084675619734214\n",
      "Cost at iteration 1500 0.08823236554878638\n",
      "Cost at iteration 2000 0.08706655950680812\n",
      "Cost at iteration 2500 0.0864574350217082\n",
      "Cost at iteration 3000 0.08610413839122685\n",
      "Cost at iteration 3500 0.0858824503319582\n",
      "Cost at iteration 4000 0.08573414959185513\n",
      "Cost at iteration 4500 0.0856294324482497\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Fit your data\n",
    "\n",
    "def logistic_regression_GD(X, Y, k, n, max_iter=1000):\n",
    "    '''\n",
    "    Inputs: \n",
    "        X shape: (m, n)\n",
    "        w shape: (n, k)\n",
    "    '''\n",
    "    W = np.random.rand(n, k)\n",
    "    l_rate = 0.01\n",
    "    for i in range(max_iter):\n",
    "        cost, grad =  gradient(X, Y, W)\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Cost at iteration {i}\", cost)\n",
    "        W = W - l_rate * grad\n",
    "    return W, i\n",
    "\n",
    "# for those who tend to feel overwhelmed with lots of code\n",
    "# I recommend you to write each part of the code separately as function\n",
    "# it helps!\n",
    "def gradient(X, Y, W):\n",
    "    m = X.shape[0]\n",
    "    H = h_theta(X, W)\n",
    "    cost = - np.sum(Y * np.log(H)) / m\n",
    "    error = H - Y\n",
    "    grad = softmax_grad(X, error)\n",
    "    return cost, grad\n",
    "\n",
    "def softmax(theta_t_x):\n",
    "    return np.exp(theta_t_x) / np.sum(np.exp(theta_t_x), axis=1, keepdims=True)\n",
    "\n",
    "def softmax_grad(X, error):\n",
    "    return  X.T @ error\n",
    "        \n",
    "def h_theta(X, W):\n",
    "    '''\n",
    "    Input:\n",
    "        X shape: (m, n)\n",
    "        w shape: (n, k)\n",
    "    Returns:\n",
    "        yhat shape: (m, k)\n",
    "    '''\n",
    "    return softmax(X @ W)\n",
    "\n",
    "W, i = logistic_regression_GD(X_train, Y_train_encoded, k, X_train.shape[1], max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = np.argmax(h_theta(X_test, W), axis=1)\n",
    "accuracy_score(y_test, yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
